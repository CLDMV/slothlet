# üöÄ Slothlet Performance Analysis

> **Comprehensive benchmarks comparing eager vs lazy loading strategies**

This document provides detailed performance analysis of Slothlet's loading modes based on real-world benchmarks. All tests are reproducible using `npm run test:performance`.

## üìä Executive Summary

> [!NOTE]
> **Performance Winner Depends on Your Use Case**
>
> | Metric              | Lazy Mode           | Eager Mode   | Winner       | Improvement     |
> | ------------------- | ------------------- | ------------ | ------------ | --------------- |
> | **Startup Time**    | 7.92ms              | 27.92ms      | üéØ **Lazy**  | **3.5x faster** |
> | **Function Calls**  | 1.14Œºs              | 1.23Œºs       | ‚âà **Equal**  | **Within 8%**   |
> | **Realistic Usage** | 1.14Œºs              | 1.23Œºs       | ‚âà **Equal**  | **Within 8%**   |
> | **Memory Usage**    | On-demand           | Full upfront | üéØ **Lazy**  | Scales with use |
> | **Predictability**  | Variable first-call | Consistent   | üöÄ **Eager** | No surprises    |

### Key Takeaways

> [!TIP]
> **Choose your loading strategy based on your specific needs:**
>
> - ‚úÖ **Lazy mode excels at startup** - 3.5x faster initialization
> - ‚úÖ **Both modes equal at runtime** - Post-materialization performance identical (within measurement noise)
> - ‚úÖ **Materialization cost is one-time** - ~650-970Œºs per module, only on first access
> - ‚úÖ **Both modes are production-ready** with different optimization targets

---

## üî¨ Detailed Benchmark Results

### Startup Performance Comparison

```text
üìä Startup Time Analysis (Aggregated - January 13, 2026)
======================================
Eager Mode:  27.92ms (avg) | 26.06ms (min) | 36.06ms (max)
Lazy Mode:   7.92ms (avg) | 6.87ms (min) | 36.19ms (max)

Winner: Lazy mode (3.5x faster)
```

**Why Lazy Startup Wins:**

- ‚úÖ No upfront module loading and compilation
- ‚úÖ Deferred file system operations
- ‚úÖ Minimal initial memory allocation
- ‚úÖ Scales with actual usage, not potential usage

### Function Call Performance Comparison

```text
üìä Function Call Analysis (Aggregated - January 13, 2026)
===============================================
Eager Calls:       1.23Œºs (avg) | 0.70Œºs (min) | 49.80Œºs (max)
Lazy Subsequent:   1.14Œºs (avg) | 0.70Œºs (min) | 29.20Œºs (max)
Lazy First Call:   650-970Œºs (materialization overhead, varies by module)

Winner: Equal (within 8% measurement noise)
```

**Why Performance is Now Equal:**

- ‚úÖ **Fixed \_\_slothletPath assignment** - Eager mode now pre-assigns paths during loading
- ‚úÖ **No runtime property definition** - Eliminated Object.defineProperty overhead in wrapper
- ‚úÖ **Identical code paths** - Post-materialization, both modes execute the same functions
- ‚úÖ **8% difference is measurement noise** - Sub-microsecond timing inherently variable

### Realistic API Usage Performance

```text
üìä Realistic Usage (500 iterations, 41 unique API calls)
=========================================================
Eager Mode:  1.23Œºs (avg) | 0.60Œºs (min) | 16.80Œºs (max)
Lazy Mode:   1.14Œºs (avg) | 0.50Œºs (min) | 16.80Œºs (max)

Winner: Equal (within 8% measurement noise)
```

**Performance Parity Achieved:**

- ‚úÖ Tests diverse API usage patterns from actual test suite
- ‚úÖ 41 unique function calls across all modules
- ‚úÖ Both modes perform identically in real-world scenarios
- ‚úÖ Differences within statistical noise at sub-microsecond scale

### Materialization Analysis

```text
üìä Lazy Mode Materialization Breakdown
====================================================
Module Type                    | First Call | Subsequent | Benefit
-------------------------------|------------|------------|--------
math/math.mjs (nested)         | ~650Œºs     | 1.1Œºs      | 590x
string/string.mjs (flattened)  | ~750Œºs     | 1.0Œºs      | 750x
funcmod/funcmod.mjs (callable) | ~970Œºs     | 0.9Œºs      | 1078x

Average materialization cost: ~790Œºs per module (one-time)
```

**Materialization Insights:**

- ‚úÖ One-time cost per module (not per function call)
- ‚úÖ Deeper nesting = higher initial cost, same final performance
- ‚úÖ Complex modules show bigger relative improvements
- ‚úÖ Post-materialization performance equals eager mode

---

## üéØ Performance Recommendations

### Choose **Lazy Mode** When:

üéØ **Fast startup is critical** (3.5x faster)

- Serverless functions with cold starts
- CLI tools that need instant responsiveness
- Development environments with frequent restarts

üéØ **Memory efficiency matters**

- Large APIs with many unused endpoints
- Resource-constrained environments
- Microservices using subset functionality

üéØ **Usage patterns are sparse**

### Choose **Lazy Mode** When:

üéØ **Fast startup is critical** (3.5x faster)

- Serverless functions with cold starts
- CLI tools that need instant responsiveness
- Development environments with frequent restarts

üéØ **Partial API usage expected**

- Only 20-50% of API surface area used
- Conditional feature loading
- Plugin-based architectures

üéØ **Memory efficiency matters**

- Resource-constrained environments
- Multi-tenant applications
- Microservices with many instances

### Choose **Eager Mode** When:

üöÄ **Predictable behavior is required**

- Production systems requiring consistent latency
- Applications sensitive to timing variations
- When first-call materialization delays are unacceptable

üöÄ **Full API usage expected**

- Using 80%+ of available modules
- Batch processing systems
- Long-running applications where startup time is amortized

üöÄ **Simpler mental model preferred**

- All modules loaded upfront
- No materialization surprises
- Traditional synchronous initialization

**Note:** Function call performance is now equal between modes (within 8% measurement noise).

---

## ‚öñÔ∏è Trade-off Analysis

### Performance Characteristics

| Aspect              | Lazy Mode       | Eager Mode      |
| ------------------- | --------------- | --------------- |
| **Startup**         | 7.92ms ‚ö°       | 27.92ms üêå      |
| **Function Calls**  | 1.14Œºs ‚âà        | 1.23Œºs ‚âà        |
| **Realistic Usage** | 1.14Œºs ‚âà        | 1.23Œºs ‚âà        |
| **First Access**    | ~790Œºs overhead | Instant         |
| **Memory**          | On-demand ‚ö°    | Full upfront üêå |
| **Predictability**  | Variable üêå     | Consistent ‚ö°   |

**Legend:** ‚ö° Winner | üêå Slower | ‚âà Equal (within measurement noise)

### Real-World Scenarios

**Lazy Mode Wins:**

```javascript
// Scenario: CLI tool using 2 out of 20 modules
Startup: 7.92ms vs 27.92ms = 3.5x faster ‚ö°
Memory: ~10% usage vs 100% = 90% savings ‚ö°
Total time: 7.92ms + (2 √ó 0.79ms) = 9.5ms vs 27.92ms
Function calls: 1.14Œºs vs 1.23Œºs = Equal (within 8%)
```

**Eager Mode Wins (Predictability):**

```javascript
// Scenario: Production API where consistent latency is critical
Startup: 27.92ms (one-time cost, amortized over lifetime)
Function calls: 1.23Œºs = Equal to lazy (within 8%)
First access: Instant (no materialization delay) ‚ö°
Predictability: No timing surprises ‚ö°
```

**Both Modes Equal:**

```javascript
// Function call performance after lazy materialization
Lazy:  1.14Œºs per call
Eager: 1.23Œºs per call
Difference: 8% (within measurement noise at sub-microsecond scale)
Conclusion: Performance parity achieved ‚úÖ
```

---

## üîß Benchmark Methodology

### Test Environment

- **Node.js**: v22+ (development conditions)
- **Platform**: Windows 11
- **Test Suite**: 200+ iterations per measurement for statistical accuracy
- **API Directory**: `api_tests/api_test` (25+ modules)

### Module Categories Tested

**Root Modules (immediate load in lazy mode):**

- `root-function.mjs` ‚Üí `rootFunction`
- `root-math.mjs` ‚Üí `rootMath`
- `rootstring.mjs` ‚Üí `rootstring`
- `config.mjs` ‚Üí `config`

**Nested Modules (on-demand materialization in lazy mode):**

- `math/math.mjs` ‚Üí `math`
- `string/string.mjs` ‚Üí `string`
- `funcmod/funcmod.mjs` ‚Üí `funcmod`
- `nested/date/date.mjs` ‚Üí `nested.date`
- `util/*` ‚Üí `util.*`

### Bidirectional Testing

Our benchmarks use a bidirectional approach to account for JIT compiler effects:

1. **Lazy-First Test**: Run lazy mode first, then eager mode
2. **Eager-First Test**: Run eager mode first, then lazy mode
3. **Aggregated Results**: Average results from both test orders

This methodology reveals:

- **High variance detection**: Identifies unreliable measurements
- **JIT warmup effects**: Shows compiler optimization impacts
- **Caching interference**: Detects cross-test contamination

### Verification Steps

- ‚úÖ Function results identical between modes
- ‚úÖ Function references become identical post-materialization
- ‚úÖ 200+ iterations for statistical significance
- ‚úÖ Fresh instances to avoid caching artifacts
- ‚úÖ Bidirectional testing to account for order effects

---

## üìä Detailed Performance Results

### Comprehensive Benchmark Data

```text
üìä AGGREGATED PERFORMANCE RESULTS
================================

üöÄ STARTUP PERFORMANCE:
   Eager: 27.92ms (avg) | Range: 26.06ms - 36.06ms
   Lazy:  7.92ms (avg) | Range: 6.87ms - 36.19ms
   Winner: Lazy mode (3.5x faster)

‚ö° FUNCTION CALL PERFORMANCE:
   Eager:             1.23Œºs (avg)
   Lazy (first):      790Œºs (materialization)
   Lazy (subsequent): 1.14Œºs (avg)
   Winner: Equal (within 8% measurement noise)

üéØ COMPLEX MODULE PERFORMANCE:
   Eager:             1.30Œºs (avg)
   Lazy (first):      850Œºs (materialization)
   Lazy (subsequent): 1.25Œºs (avg)
   Winner: Equal (within 4% measurement noise)

üîÑ MULTI-MODULE ACCESS PATTERNS:

   Nested Math Module (math/math.mjs):
     Eager:             1.30Œºs
     Lazy (subsequent): 1.29Œºs
     Winner: Equal (within measurement noise)

   String Module (string/string.mjs):
     Eager:             1.17Œºs
     Lazy (subsequent): 1.02Œºs
     Winner: Equal (within measurement noise)

   Callable Function Module (funcmod/funcmod.mjs):
     Eager:             1.05Œºs
     Lazy (subsequent): 0.88Œºs
     Winner: Equal (within measurement noise)
```

### Performance Variance Analysis

> [!WARNING] > **Performance can vary significantly due to JIT compiler effects and system conditions.**
>
> These benchmarks represent a single test run. For production decisions, run multiple tests with your specific API structure and usage patterns.

```text
üìà BENCHMARK NOTES
==================

üí° MEASUREMENT CONSIDERATIONS:
   ‚Ä¢ JIT compiler effects can cause variance between runs
   ‚Ä¢ System load and background processes affect timing
   ‚Ä¢ First-run vs subsequent-run performance differs
   ‚Ä¢ Results are indicative, not absolute guarantees
   ‚Ä¢ Your mileage may vary based on actual usage patterns
```

---

## üìè Raw Performance Data

```text
Benchmark Results (Aggregated - January 13, 2026)
==================================================
‚Ä¢ Eager startup:       27.92ms
‚Ä¢ Lazy startup:        7.92ms
‚Ä¢ Eager calls:         1.23Œºs
‚Ä¢ Lazy calls:          1.14Œºs
‚Ä¢ Materialization:     790Œºs (average per module)

Performance Ratios:
‚Ä¢ Startup ratio:       3.5x faster (lazy)
‚Ä¢ Call ratio:          Equal (within 8% measurement noise)
‚Ä¢ Materialization:     ~693x improvement (790Œºs ‚Üí 1.14Œºs)
```

### Individual Module Performance

```text
üîç PER-MODULE MATERIALIZATION BREAKDOWN
=======================================

math/math.mjs (nested structure):
  First Call:    ~650Œºs (materialization)
  Subsequent:    1.20Œºs (materialized)
  Benefit:       540x faster after materialization

string/string.mjs (flattened):
  First Call:    ~750Œºs (materialization)
  Subsequent:    1.10Œºs (materialized)
  Benefit:       680x faster after materialization

funcmod/funcmod.mjs (callable):
  First Call:    ~970Œºs (materialization)
  Subsequent:    1.00Œºs (materialized)
  Benefit:       970x faster after materialization
```

---

## üöÄ Getting Started

### Running Benchmarks

```bash
# Set development environment (loads from src/ instead of dist/)
set NODE_ENV=development
set NODE_OPTIONS=--conditions=development

# Run the comprehensive performance test suite
npm run test:performance

# Or run directly
node tests/performance-benchmark.mjs
```

### Quick Performance Test

#### ESM (ES Modules)

```javascript
import slothlet from "@cldmv/slothlet";

console.time("eager-startup");
const eagerApi = await slothlet({ lazy: false, dir: "./api_tests/api_test" });
console.timeEnd("eager-startup");

console.time("lazy-startup");
const lazyApi = await slothlet({ lazy: true, dir: "./api_tests/api_test" });
console.timeEnd("lazy-startup");

// Test your specific usage patterns
console.time("eager-calls");
for (let i = 0; i < 1000; i++) {
	eagerApi.math.add(2, 3);
}
console.timeEnd("eager-calls");

console.time("lazy-calls");
for (let i = 0; i < 1000; i++) {
	await lazyApi.math.add(2, 3);
}
console.timeEnd("lazy-calls");
```

#### CommonJS (CJS)

```javascript
const slothlet = require("@cldmv/slothlet");

async function performanceTest() {
	console.time("eager-startup");
	const eagerApi = await slothlet({ lazy: false, dir: "./api_tests/api_test" });
	console.timeEnd("eager-startup");

	console.time("lazy-startup");
	const lazyApi = await slothlet({ lazy: true, dir: "./api_tests/api_test" });
	console.timeEnd("lazy-startup");

	// Test your specific usage patterns
	console.time("eager-calls");
	for (let i = 0; i < 1000; i++) {
		eagerApi.math.add(2, 3);
	}
	console.timeEnd("eager-calls");

	console.time("lazy-calls");
	for (let i = 0; i < 1000; i++) {
		await lazyApi.math.add(2, 3);
	}
	console.timeEnd("lazy-calls");
}

performanceTest().catch(console.error);
```

---

## üí° Performance Tips

### For Lazy Mode Optimization

- ‚úÖ **Organize frequently-used modules as root-level files** (loaded immediately)
- ‚úÖ **Keep materialization costs low** with simple module exports
- ‚úÖ **Consider pre-warming critical modules** if first-call latency matters
- ‚úÖ **Profile actual usage patterns** to validate lazy mode benefits
- ‚úÖ **Use shallow nesting** when possible for faster materialization

### For Eager Mode Optimization

- ‚úÖ **Optimize module loading order** for faster startup
- ‚úÖ **Use tree-shaking** to reduce bundle size in build processes
- ‚úÖ **Profile memory usage** in production environments
- ‚úÖ **Prefer eager for high-frequency call paths** (> 1000 calls/second)
- ‚úÖ **Consider eager in memory-abundant environments**

### General Performance Optimization

- ‚úÖ **Avoid deep nesting** when possible (increases materialization time)
- ‚úÖ **Use meaningful module names** for better debugging and profiling
- ‚úÖ **Profile your specific workload** rather than relying solely on benchmarks
- ‚úÖ **Monitor real-world performance metrics** in production
- ‚úÖ **Consider hybrid approaches** (eager for core, lazy for optional features)

### Development vs Production Considerations

**Development Mode:**

- Loads from `src/` directory
- More detailed error messages
- Higher startup overhead
- Use lazy mode for faster iteration

**Production Mode:**

- Loads from `dist/` directory
- Optimized transpiled code
- Lower overhead across the board
- Consider eager mode for predictable performance

---

## üîç Statistical Notes

### Measurement Accuracy

- **Microsecond precision**: Inherent variance in sub-millisecond measurements
- **JIT compiler effects**: First runs may show different performance characteristics
- **System load impact**: Background processes can affect timing
- **Memory pressure**: Available system memory affects performance

### Benchmark Limitations

- **Synthetic workloads**: May not reflect real-world usage patterns
- **Single-threaded**: Node.js single-threaded nature affects results
- **Platform-specific**: Results may vary on different operating systems
- **Node.js version**: Performance characteristics change between Node.js versions

### Recommendations for Your Application

1. **Run your own benchmarks** with your actual API structure
2. **Test with your expected usage patterns** (module access frequency)
3. **Measure in your target deployment environment**
4. **Consider both startup and runtime performance** for your use case
5. **Profile memory usage** if running in constrained environments

---

**üìä Performance analysis updated: January 13, 2026**  
**üî¨ Based on slothlet v2.12.0 with \_\_slothletPath performance fix**  
**üìà All metrics from `tests/performance/performance-benchmark-aggregated.mjs`**
