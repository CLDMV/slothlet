# üöÄ Slothlet Performance Analysis

> **Comprehensive benchmarks comparing eager vs lazy loading strategies**

This document provides detailed performance analysis of Slothlet's loading modes based on real-world benchmarks. All tests are reproducible using `npm run test:performance`.

## üìä Executive Summary

> [!NOTE] > **Performance Winner Depends on Your Use Case**
>
> | Metric             | Lazy Mode           | Eager Mode   | Winner       | Improvement       |
> | ------------------ | ------------------- | ------------ | ------------ | ----------------- |
> | **Startup Time**   | 4.89ms              | 14.29ms      | üéØ **Lazy**  | **2.9x faster**   |
> | **Function Calls** | 0.99Œºs              | 0.90Œºs       | üöÄ **Eager** | **1.1x faster**   |
> | **Memory Usage**   | On-demand           | Full upfront | üéØ **Lazy**  | Scales with usage |
> | **Predictability** | Variable first-call | Consistent   | üöÄ **Eager** | No surprises      |

### Key Takeaways

> [!TIP] > **Choose your loading strategy based on your specific needs:**
>
> - ‚úÖ **Lazy mode excels at startup** - 2.9x faster initialization
> - ‚úÖ **Eager mode excels at runtime** - 1.1x faster function calls
> - ‚úÖ **Materialization cost is minimal** - ~371Œºs one-time overhead per module
> - ‚úÖ **Both modes are production-ready** with different optimization targets

---

## üî¨ Detailed Benchmark Results

### Startup Performance Comparison

```text
üìä Startup Time Analysis
========================
Eager Mode:  14.29ms (avg) | 11.82ms (min) | 41.17ms (max)
Lazy Mode:   4.89ms (avg) | 3.62ms (min) | 42.20ms (max)

Winner: Lazy mode (2.9x faster)
```

**Why Lazy Startup Wins:**

- ‚úÖ No upfront module loading and compilation
- ‚úÖ Deferred file system operations
- ‚úÖ Minimal initial memory allocation
- ‚úÖ Scales with actual usage, not potential usage

### Function Call Performance Comparison

```text
üìä Function Call Analysis (aggregated benchmark)
===============================================
Eager Calls:       0.90Œºs (avg) | 0.60Œºs (min) | 41.70Œºs (max)
Lazy Subsequent:   0.99Œºs (avg) | 0.60Œºs (min) | 43.70Œºs (max)
Lazy First Call:   371Œºs (materialization overhead)

Winner: Eager mode (1.1x faster)
```

**Why Eager Function Calls Win:**

- ‚úÖ No proxy overhead after startup
- ‚úÖ Direct function references without wrapping
- ‚úÖ Consistent performance characteristics
- ‚úÖ V8 can optimize more aggressively with stable references

### Materialization Analysis

```text
üìä Lazy Mode Materialization Breakdown
======================================
Module Type                    | First Call | Subsequent | Benefit
-------------------------------|------------|------------|--------
math/math.mjs (nested)         | 316.10Œºs   | 0.82Œºs     | 385.5x
string/string.mjs (flattened)  | 277.93Œºs   | 1.12Œºs     | 248.2x
funcmod/funcmod.mjs (callable) | 283.35Œºs   | 0.91Œºs     | 311.4x

Average materialization cost: ~371Œºs per module
```

**Materialization Insights:**

- ‚úÖ One-time cost per module (not per function call)
- ‚úÖ Deeper nesting = higher initial cost, same final performance
- ‚úÖ Complex modules show bigger relative improvements
- ‚úÖ Post-materialization performance approaches eager mode

---

## üéØ Performance Recommendations

### Choose **Lazy Mode** When:

üéØ **Fast startup is critical** (2.9x faster)

- Serverless functions with cold starts
- CLI tools that need instant responsiveness
- Development environments with frequent restarts

üéØ **Memory efficiency matters**

- Large APIs with many unused endpoints
- Resource-constrained environments
- Microservices using subset functionality

üéØ **Usage patterns are sparse**

- Only 20-50% of API surface area used
- Conditional feature loading
- Plugin-based architectures

### Choose **Eager Mode** When:

üöÄ **Function call performance is critical**

- High-throughput applications
- Real-time processing systems
- Performance-sensitive inner loops

üöÄ **Predictable behavior is required**

- Production systems requiring consistent latency
- Applications sensitive to timing variations
- When materialization delays are unacceptable

üöÄ **Full API usage expected**

- Using 80%+ of available modules
- Batch processing systems
- Long-running applications

---

## ‚öñÔ∏è Trade-off Analysis

### Performance Characteristics

| Aspect             | Lazy Mode       | Eager Mode      |
| ------------------ | --------------- | --------------- |
| **Startup**        | 4.89ms ‚ö°       | 14.29ms üêå      |
| **Function Calls** | 0.99Œºs üêå       | 0.90Œºs ‚ö°       |
| **First Access**   | ~371Œºs overhead | Instant         |
| **Memory**         | On-demand ‚ö°    | Full upfront üêå |
| **Predictability** | Variable üêå     | Consistent ‚ö°   |

### Real-World Scenarios

**Lazy Mode Wins:**

```javascript
// Scenario: CLI tool using 2 out of 20 modules
Startup: 4.89ms vs 14.29ms = 2.9x faster
Memory: ~10% usage vs 100% = 90% savings
Total time: 4.89ms + (2 √ó 0.371ms) = 5.63ms vs 14.29ms
```

**Eager Mode Wins:**

```javascript
// Scenario: High-throughput API using most modules
Consistent latency: No materialization surprises
Function calls: 0.90Œºs vs 0.99Œºs = 1.1x faster (eager)
Note: For call-intensive workloads, eager's predictability and speed win
```

---

## üîß Benchmark Methodology

### Test Environment

- **Node.js**: v22+ (development conditions)
- **Platform**: Windows 11
- **Test Suite**: 200+ iterations per measurement for statistical accuracy
- **API Directory**: `api_tests/api_test` (25+ modules)

### Module Categories Tested

**Root Modules (immediate load in lazy mode):**

- `root-function.mjs` ‚Üí `rootFunction`
- `root-math.mjs` ‚Üí `rootMath`
- `rootstring.mjs` ‚Üí `rootstring`
- `config.mjs` ‚Üí `config`

**Nested Modules (on-demand materialization in lazy mode):**

- `math/math.mjs` ‚Üí `math`
- `string/string.mjs` ‚Üí `string`
- `funcmod/funcmod.mjs` ‚Üí `funcmod`
- `nested/date/date.mjs` ‚Üí `nested.date`
- `util/*` ‚Üí `util.*`

### Bidirectional Testing

Our benchmarks use a bidirectional approach to account for JIT compiler effects:

1. **Lazy-First Test**: Run lazy mode first, then eager mode
2. **Eager-First Test**: Run eager mode first, then lazy mode
3. **Aggregated Results**: Average results from both test orders

This methodology reveals:

- **High variance detection**: Identifies unreliable measurements
- **JIT warmup effects**: Shows compiler optimization impacts
- **Caching interference**: Detects cross-test contamination

### Verification Steps

- ‚úÖ Function results identical between modes
- ‚úÖ Function references become identical post-materialization
- ‚úÖ 200+ iterations for statistical significance
- ‚úÖ Fresh instances to avoid caching artifacts
- ‚úÖ Bidirectional testing to account for order effects

---

## üìä Detailed Performance Results

### Comprehensive Benchmark Data

```text
üìä AGGREGATED PERFORMANCE RESULTS
================================

üöÄ STARTUP PERFORMANCE:
   Eager: 14.29ms (avg) | Range: 11.82ms - 41.17ms
   Lazy:  4.89ms (avg) | Range: 3.62ms - 42.20ms
   Winner: Lazy mode (2.9x faster)

‚ö° FUNCTION CALL PERFORMANCE:
   Eager:             0.90Œºs (avg)
   Lazy (first):      371Œºs (materialization)
   Lazy (subsequent): 0.99Œºs (avg)
   Winner: Eager mode (1.1x faster)

üéØ COMPLEX MODULE PERFORMANCE:
   Eager:             0.91Œºs (avg)
   Lazy (first):      440Œºs (materialization)
   Lazy (subsequent): 0.98Œºs (avg)
   Winner: Eager mode (1.1x faster)

üîÑ MULTI-MODULE ACCESS PATTERNS:

   Nested Math Module (math/math.mjs):
     Eager:             0.89Œºs
     Lazy (subsequent): 0.98Œºs
     Winner: Eager (1.1x faster)

   String Module (string/string.mjs):
     Eager:             1.08Œºs
     Lazy (subsequent): 1.26Œºs
     Winner: Eager (1.2x faster)

   Callable Function Module (funcmod/funcmod.mjs):
     Eager:             0.57Œºs
     Lazy (subsequent): 0.91Œºs
     Winner: Eager (1.6x faster)
```

### Performance Variance Analysis

> [!WARNING] > **Performance can vary significantly due to JIT compiler effects and system conditions.**
>
> These benchmarks represent a single test run. For production decisions, run multiple tests with your specific API structure and usage patterns.

```text
üìà BENCHMARK NOTES
==================

üí° MEASUREMENT CONSIDERATIONS:
   ‚Ä¢ JIT compiler effects can cause variance between runs
   ‚Ä¢ System load and background processes affect timing
   ‚Ä¢ First-run vs subsequent-run performance differs
   ‚Ä¢ Results are indicative, not absolute guarantees
   ‚Ä¢ Your mileage may vary based on actual usage patterns
```

---

## üìè Raw Performance Data

```text
Benchmark Results (Latest Run - December 30, 2025)
===================================================
‚Ä¢ Eager startup:       14.29ms
‚Ä¢ Lazy startup:        4.89ms
‚Ä¢ Eager calls:         0.90Œºs
‚Ä¢ Lazy calls:          0.99Œºs
‚Ä¢ Materialization:     371Œºs (average per module)

Performance Ratios:
‚Ä¢ Startup ratio:       2.9x faster (lazy)
‚Ä¢ Call ratio:          1.1x faster (eager)
‚Ä¢ Materialization:     ~375x improvement (371Œºs ‚Üí 0.99Œºs)
```

### Individual Module Performance

```text
üîç PER-MODULE MATERIALIZATION BREAKDOWN
=======================================

math/math.mjs (nested structure):
  First Call:    316.10Œºs (materialization)
  Subsequent:    0.82Œºs (materialized)
  Benefit:       385.5x faster after materialization

string/string.mjs (flattened):
  First Call:    277.93Œºs (materialization)
  Subsequent:    1.12Œºs (materialized)
  Benefit:       248.2x faster after materialization

funcmod/funcmod.mjs (callable):
  First Call:    283.35Œºs (materialization)
  Subsequent:    0.91Œºs (materialized)
  Benefit:       311.4x faster after materialization
```

---

## üöÄ Getting Started

### Running Benchmarks

```bash
# Set development environment (loads from src/ instead of dist/)
set NODE_ENV=development
set NODE_OPTIONS=--conditions=development

# Run the comprehensive performance test suite
npm run test:performance

# Or run directly
node tests/performance-benchmark.mjs
```

### Quick Performance Test

#### ESM (ES Modules)

```javascript
import slothlet from "@cldmv/slothlet";

console.time("eager-startup");
const eagerApi = await slothlet({ lazy: false, dir: "./api_tests/api_test" });
console.timeEnd("eager-startup");

console.time("lazy-startup");
const lazyApi = await slothlet({ lazy: true, dir: "./api_tests/api_test" });
console.timeEnd("lazy-startup");

// Test your specific usage patterns
console.time("eager-calls");
for (let i = 0; i < 1000; i++) {
	eagerApi.math.add(2, 3);
}
console.timeEnd("eager-calls");

console.time("lazy-calls");
for (let i = 0; i < 1000; i++) {
	await lazyApi.math.add(2, 3);
}
console.timeEnd("lazy-calls");
```

#### CommonJS (CJS)

```javascript
const slothlet = require("@cldmv/slothlet");

async function performanceTest() {
	console.time("eager-startup");
	const eagerApi = await slothlet({ lazy: false, dir: "./api_tests/api_test" });
	console.timeEnd("eager-startup");

	console.time("lazy-startup");
	const lazyApi = await slothlet({ lazy: true, dir: "./api_tests/api_test" });
	console.timeEnd("lazy-startup");

	// Test your specific usage patterns
	console.time("eager-calls");
	for (let i = 0; i < 1000; i++) {
		eagerApi.math.add(2, 3);
	}
	console.timeEnd("eager-calls");

	console.time("lazy-calls");
	for (let i = 0; i < 1000; i++) {
		await lazyApi.math.add(2, 3);
	}
	console.timeEnd("lazy-calls");
}

performanceTest().catch(console.error);
```

---

## üí° Performance Tips

### For Lazy Mode Optimization

- ‚úÖ **Organize frequently-used modules as root-level files** (loaded immediately)
- ‚úÖ **Keep materialization costs low** with simple module exports
- ‚úÖ **Consider pre-warming critical modules** if first-call latency matters
- ‚úÖ **Profile actual usage patterns** to validate lazy mode benefits
- ‚úÖ **Use shallow nesting** when possible for faster materialization

### For Eager Mode Optimization

- ‚úÖ **Optimize module loading order** for faster startup
- ‚úÖ **Use tree-shaking** to reduce bundle size in build processes
- ‚úÖ **Profile memory usage** in production environments
- ‚úÖ **Prefer eager for high-frequency call paths** (> 1000 calls/second)
- ‚úÖ **Consider eager in memory-abundant environments**

### General Performance Optimization

- ‚úÖ **Avoid deep nesting** when possible (increases materialization time)
- ‚úÖ **Use meaningful module names** for better debugging and profiling
- ‚úÖ **Profile your specific workload** rather than relying solely on benchmarks
- ‚úÖ **Monitor real-world performance metrics** in production
- ‚úÖ **Consider hybrid approaches** (eager for core, lazy for optional features)

### Development vs Production Considerations

**Development Mode:**

- Loads from `src/` directory
- More detailed error messages
- Higher startup overhead
- Use lazy mode for faster iteration

**Production Mode:**

- Loads from `dist/` directory
- Optimized transpiled code
- Lower overhead across the board
- Consider eager mode for predictable performance

---

## üîç Statistical Notes

### Measurement Accuracy

- **Microsecond precision**: Inherent variance in sub-millisecond measurements
- **JIT compiler effects**: First runs may show different performance characteristics
- **System load impact**: Background processes can affect timing
- **Memory pressure**: Available system memory affects performance

### Benchmark Limitations

- **Synthetic workloads**: May not reflect real-world usage patterns
- **Single-threaded**: Node.js single-threaded nature affects results
- **Platform-specific**: Results may vary on different operating systems
- **Node.js version**: Performance characteristics change between Node.js versions

### Recommendations for Your Application

1. **Run your own benchmarks** with your actual API structure
2. **Test with your expected usage patterns** (module access frequency)
3. **Measure in your target deployment environment**
4. **Consider both startup and runtime performance** for your use case
5. **Profile memory usage** if running in constrained environments

---

**üìä Performance analysis updated: December 30, 2025**  
**üî¨ Based on slothlet v2.8.0 with controlled performance testing methodology**
